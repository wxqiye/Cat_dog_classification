{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e7d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入\n",
    "import os,shutil\n",
    "from torch.utils import data\n",
    "from torchvision import transforms,datasets\n",
    "import numpy as np\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils import data\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bf3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义\n",
    "\n",
    "test_rate=0.2#训练集和验证集的比例为8:2。\n",
    "img_num=12500 \n",
    "test_num=int(img_num*test_rate)\n",
    "\n",
    "\n",
    "# import random\n",
    "# test_index = random.sample(range(0, img_num), test_num)#生成(0,img_num)的随机数。\n",
    "file_path=\"./\"\n",
    "tr=\"train\"\n",
    "te=\"test\"\n",
    "cat=\"Cat\"\n",
    "dog=\"Dog\"\n",
    "valid=\"valid\"\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "PATH='./model/final_resnet18_Cat_Dog_classification.pth'\n",
    "losses=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94752d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义保存的日志文件函数\n",
    "import logging\n",
    " \n",
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    " \n",
    "    fh = logging.FileHandler(filename, \"a\")\n",
    "    fh.setFormatter(formatter) \n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    if not logger.handlers:\n",
    "    # 将两个句柄绑定到logger\n",
    "        logger.addHandler(fh)\n",
    "        logger.addHandler(sh)\n",
    " \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c0fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms,datasets\n",
    "\n",
    "#定义transforms  数据预处理\n",
    "transforms = transforms.Compose(\n",
    "[\n",
    "transforms.Resize([256,256]),# 裁剪\n",
    "transforms.CenterCrop([224,224]),\n",
    "transforms.ToTensor(),#从0到255的值映射到0到1的范围内\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "# transforms.Scale(size),\n",
    "# transforms.CenterCrop((size, size))\n",
    "# transforms.RandomCrop\n",
    "#归一化\n",
    "] \n",
    "\n",
    ")\n",
    "#数据加载\n",
    "train_data = datasets.ImageFolder(os.path.join(file_path,tr), transforms)\n",
    "test_data=datasets.ImageFolder(os.path.join(file_path,te), transforms)\n",
    "valid_data=datasets.ImageFolder(os.path.join(file_path,valid), transforms)\n",
    "# [0，1]只是范围改变了， 并没有改变分布，mean和std处理后可以让数据正态分布\n",
    "train_loader = data.DataLoader(train_data,batch_size=batch_size,shuffle=True,pin_memory=True)\n",
    "test_loader = data.DataLoader(test_data,batch_size=batch_size)\n",
    "valid_loader = data.DataLoader(valid_data,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd83112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #%% 训练数据可视化\n",
    "# images, labels = next(iter(train_loader))\n",
    "# print(images.size())  # torch.Size([9, 1, 28, 28])\n",
    "# plt.figure(figsize=(9, 9))\n",
    "# for i in range(9):\n",
    "#     plt.subplot(3, 3, i+1)\n",
    "#     plt.title(labels[i].item())\n",
    "#     plt.imshow(images[i].permute(1, 2, 0), cmap='gray')\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b638a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#定义残差块\n",
    "class Residual(nn.Module):  #@save\n",
    "    #输入通道数，输出通道数，要不要用一乘一卷积层，步长为几\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        #两个卷积层，第一个可以指定stride，第二个不指定\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        #如果用一乘一的卷积层，这个仅仅是为了resize使x与f(x)得以相加而已\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            #两个batch_normaliztion类\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    " \n",
    "    def forward(self, X):\n",
    "        # x丢进来，卷积,bn，relu，再卷积，bn，然后y+=x，最后在relu\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "#         Y = F.relu(self.conv1(X))\n",
    "#         Y = self.conv2(Y)\n",
    "\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "    #7*7的卷积核，步长为2，填充3，输出通道64，高宽被减半\n",
    "b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   #bn再relu\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                   #最大池化层，再减半\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    " \n",
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "# b2高宽未减半，因为b1已经减半了两次。b2高宽未减半，所以通道数也没有增加\n",
    "#  b3,b4,b5 高宽减半，通道数加倍\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "dropout1=0.5\n",
    "#再用全局平均池化层，把每一个通道数的高宽给归一，再flatten，把数据拉成一维，再使用全连接层，有多少类输出就多少\n",
    "net = nn.Sequential(b1, b2, b3, b4,b5,\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), \n",
    "#                     nn.Dropout(dropout1),\n",
    "                    nn.Linear(512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75c8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #检验\n",
    "# X = torch.rand(size=(1, 3, 224, 224))\n",
    "# for layer in net:\n",
    "#     X = layer(X)\n",
    "#     print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b7a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化模型\n",
    "model=net\n",
    "model=model.to(device)\n",
    "\n",
    "\n",
    "#     #Step 2: 初始化模型\n",
    "# model = models.resnet18()\n",
    "    \n",
    "\n",
    "#     #修改网络结构，将fc层1000个输出改为2个输出\n",
    "# fc_input_feature = model.fc.in_features\n",
    "# model.fc = nn.Linear(fc_input_feature, 2)\n",
    "\n",
    "# #     #load除最后一层的预训练权重\n",
    "# # pretrained_weight = torch.hub.load_state_dict_from_url(url='https://download.pytorch.org/models/resnet18-5c106cde.pth', progress=True)\n",
    "# # del pretrained_weight['fc.weight']\n",
    "# # del pretrained_weight['fc.bias']\n",
    "# # model.load_state_dict(pretrained_weight, strict=False)\n",
    "\n",
    "# train_loader = data.DataLoader(train_data,batch_size=batch_size,shuffle=True,pin_memory=True)\n",
    "# test_loader = data.DataLoader(test_data,batch_size=batch_size)\n",
    "# valid_loader = data.DataLoader(valid_data,batch_size=batch_size)\n",
    "\n",
    "# device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0c892e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Step 3:设置损失函数\n",
    "    criterion = nn.CrossEntropyLoss()     #交叉熵损失函数\n",
    "\n",
    "    #Step 4:选择优化器\n",
    "    LR = 0.01\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR,weight_decay=5e-4,momentum=0.9)    \n",
    "#     \n",
    "\n",
    "    #Step 5:设置学习率下降策略\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,[10], gamma=0.2,last_epoch=-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbfb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 预训练参数\n",
    "# pretrained_weight = torch.hub.load_state_dict_from_url(url='https://download.pytorch.org/models/resnet18-5c106cde.pth', progress=True)\n",
    "# del pretrained_weight['fc.weight']\n",
    "# del pretrained_weight['fc.bias']\n",
    "# model.load_state_dict(pretrained_weight, strict=False)\n",
    "# if args.pretrained:\n",
    "#     model = resnet18(pretrained=False, num_classes=10)\n",
    "#     state_dict = torch.load('weights/resnet18-f37072fd.pth')\n",
    "#     state_dict.pop('fc.weight')\n",
    "#     state_dict.pop('fc.bias')\n",
    "#     model.load_state_dict(state_dict, strict=False)\n",
    "# elif args.my_resnet or args.my_improved:\n",
    "#     model = Resnet18(num_classes=10, improved=args.my_improved)\n",
    "# else:\n",
    "#     model = resnet18(pretrained=False, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293ec150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练验证函数\n",
    "def train(model,device,train_loader,optimizer,epoch,losses,criterion,train_acc):\n",
    "    model.train()\n",
    "    acc=0 \n",
    "    correct=0#预测对了几个。\n",
    "    los=0\n",
    "    for idx,(t_data,t_target) in enumerate(train_loader):\n",
    "        t_data,t_target=t_data.to(device),t_target.to(device)\n",
    "        \n",
    "        \n",
    "        #放数据进模型，得预测，算损失函数，算精度\n",
    "        pred=model(t_data)#batch_size*2\n",
    "#         print(\"pred:\",idx,pred)\n",
    "        loss=criterion(pred,t_target)\n",
    "#         print(\"loss:\",idx,loss)\n",
    "        pred_class=pred.argmax(dim=1)#batch_size*2->batch_size*1\n",
    "#         print(\"pred_class:\",idx,pred_class)\n",
    "        correct+=pred_class.eq(t_target.view_as(pred_class)).sum().item()\n",
    "    \n",
    "    #梯度清零，用损失函数更新梯度，用梯度下降更新权重\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()       \n",
    "#         if idx%10==0:\n",
    "# #             logger.info(\"epoch:{},iteration:{},loss:{}\".format(epoch,idx,loss.item()))\n",
    "\n",
    "\n",
    "# 保存最佳准确率模型\n",
    "#     if (val_acc / batch_count) > max(best_acc, 0.7):\n",
    "#         best_acc = val_acc / batch_count\n",
    "#         with open(exp_dir + \"/result.txt\", mode='w') as f:\n",
    "#             f.write(\"best accuracy:\" + str(best_acc) + \"\\n\")\n",
    "#             f.write(\"epoch:\" + str(epoch))\n",
    "#         torch.save(net.state_dict(), exp_dir + \"/weights/best.pth\")\n",
    "\n",
    "        \n",
    "#   算精度，得损失函数            \n",
    "    acc=correct/len(train_data)\n",
    "    los=loss.item()\n",
    "    losses.append(loss.item())\n",
    "    train_acc.append(acc)\n",
    "    logger.info('Epoch:[{}/{}]\\t train_loss={:.5f}\\t train_acc={:.3f}'.format(epoch+1 , num_epochs, los, acc ))\n",
    "    \n",
    "    \n",
    "    \n",
    "def test(model,device,test_loader,test_acc):\n",
    "    model.eval()\n",
    "    acc=0\n",
    "    correct=0#预测对了几个。\n",
    "    los=0\n",
    "    \n",
    "    #停止梯度的计算\n",
    "    with torch.no_grad():\n",
    "        for idx,(t_data,t_target) in enumerate(test_loader):\n",
    "            \n",
    "            #放数据，算损失函数，算精度\n",
    "            t_data,t_target=t_data.to(device),t_target.to(device)\n",
    "            pred=model(t_data)#batch_size*2\n",
    "            loss=criterion(pred,t_target)\n",
    "            pred_class=pred.argmax(dim=1)#batch_size*2->batch_size*1           \n",
    "            correct+=pred_class.eq(t_target.view_as(pred_class)).sum().item()\n",
    "            los=loss.item() \n",
    "    acc=correct/len(test_data)\n",
    "    test_acc.append(acc)\n",
    "    logger.info('test_loss={:.5f}\\t test_acc={:.3f}'.format(los, acc))\n",
    "    \n",
    "# # 保存最优\n",
    "#     global min_loss\n",
    "#     if los < min_loss:\n",
    "#         print(f'min_loss前={min_loss}')\n",
    "#         min_loss = los\n",
    "#         print(f'save!min_loss后={min_loss},current_los={los}')\n",
    "#         torch.save(model, PATH)    \n",
    "\n",
    "    \n",
    "def valid(model,device,valid_loader):\n",
    "    model.eval()\n",
    "    acc=0\n",
    "    correct=0#预测对了几个。\n",
    "    \n",
    "    #停止计算梯度，放数据，算精度，打印结果\n",
    "    with torch.no_grad():\n",
    "        for idx,(t_data,t_target) in enumerate(valid_loader):\n",
    "            t_data,t_target=t_data.to(device),t_target.to(device)\n",
    "            pred=model(t_data)#batch_size*2\n",
    "            pred_class=pred.argmax(dim=1)#batch_size*2->batch_size*1 \n",
    "            print(\"本来类\",[\"猫\" if x==0 else \"狗\" for x in t_target])\n",
    "            print(\"预测类\",[\"猫\" if x==0 else \"狗\" for x in pred_class])\n",
    "            correct+=pred_class.eq(t_target.view_as(pred_class)).sum().item()\n",
    "    acc=correct/len(valid_data)\n",
    "    logger.info('valid_acc={:.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f6b84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937b4ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-15 22:31:42,612][3620330065.py][line:7][INFO] start training!\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "num_epochs=10\n",
    "epochs=range(1,num_epochs+1)\n",
    "from time import *\n",
    "begin_time=time()\n",
    "logger = get_logger('./log/final_resnet18_Cat_Dog_classification.log')\n",
    "logger.info('start training!')\n",
    "# 训练，验证，使用scheduler更新学习率\n",
    "for epoch in range(num_epochs):\n",
    "    train(model,device,train_loader,optimizer,epoch,losses,criterion,train_acc)\n",
    "    test(model,device,test_loader,test_acc)  \n",
    "    scheduler.step()\n",
    "# test(model,device,test_loader)\n",
    "end_time=time()                      \n",
    "logger.info('finish training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491831dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘图\n",
    "import matplotlib.pyplot as plt\n",
    "epochs=range(1,num_epochs+1)\n",
    "# epochs=range(1,12)\n",
    "# train_acc.pop()\n",
    "# test_acc.pop()\n",
    "# losses.pop()\n",
    "print(f'train_acc{len(train_acc)},test_acc{(test_acc)},losses{len(losses)}')\n",
    "plt.plot(epochs,train_acc,color='r',label='train_acc') # r表示红色\n",
    "plt.plot(epochs,test_acc,color='b',label='test_acc') \n",
    "plt.plot(epochs,losses,color=(0,0,0),label='loss') #也可以用RGB值表示颜色\n",
    "#####非必须内容#########\n",
    "plt.xlabel('epochs') #x轴表示\n",
    "plt.ylabel('y label') #y轴表示\n",
    "plt.title(\"resnet18\") #图标标题表示\n",
    "plt.legend()  #每条折线的label显示\n",
    "#######################\n",
    "plt.savefig('./resnet18.jpg') #保存图片\n",
    "plt.show()  #显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0113a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存权重跟模型\n",
    "PATH='./model/final_change_resnet18_Cat_Dog_classification.pth'\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba952385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读取权重与模型并测试\n",
    "new_model = models.resnet18()    \n",
    "new_model = torch.load(PATH)\n",
    "new_model.eval()\n",
    "new_model.to(device)\n",
    "logger.info('start testing!')\n",
    "valid(new_model,device,valid_loader)  \n",
    "logger.info('finish testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8832646a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a0ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
